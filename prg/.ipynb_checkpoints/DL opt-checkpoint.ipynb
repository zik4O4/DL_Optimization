{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aea5062-48a8-4837-888b-7f424e111ea9",
   "metadata": {},
   "source": [
    "<h1 style=\"color:darkblue; text-align:center;\">DL Models Optimization: Pruning, Quantization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0d5f3-32f9-45f8-baa6-6d43b4fbd407",
   "metadata": {},
   "source": [
    "Pruning et Quantization sont deux méthodes d'optimisation de modèles de deep learning, utilisées pour\n",
    "Réduire la taille du modèle ,Accélérer l’inférence ... ,Dans ce tutoriel, nous allons :\n",
    "\n",
    "1)Entraîner un modèle de reconnaissance de chiffres manuscrits sur le dataset MNIST\n",
    "\n",
    "2)Appliquer deux techniques d’optimisation :\n",
    "\n",
    " 3)Comparer les tailles et performances des modèles optimisés\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0793a724-caa6-45a3-b433-d80aa3b48571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 22:59:28.908275: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297f1f76-ffc4-47f3-a034-7c4005b6145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941da0f9-5d12-492a-a28d-f7d60c195c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a19536-4575-4b57-9582-23974c47dfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59bbe5cf-dd01-47ba-ba76-5810f19d31e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f495b76-b5ef-4ed8-91e3-1012b91650cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x142d62480>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80561323-e7b3-493c-95c0-84c262f97131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db268811-6194-45f1-a8b9-059d3d9cb3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a74a99ad-ea2a-4f80-beab-9117d32e4d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 17s 2ms/step - loss: 0.2734 - accuracy: 0.9226\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1233 - accuracy: 0.9637\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0866 - accuracy: 0.9742\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0668 - accuracy: 0.9795\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0522 - accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x1488dc260>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')  # Correction: changé sigmoid en softmax pour classification multinomiale\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d252cd9-6fd5-4180-8eec-96c065204171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0792 - accuracy: 0.9747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07916077971458435, 0.9746999740600586]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba766ade-35cc-489d-b8b8-c3a3a7500ff7",
   "metadata": {},
   "source": [
    "<h3 style='color:blue'>(1) Pruning (taille réduite du modèle)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99153a18-fb39-43a6-90c5-ed6b9859942c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1688/1688 [==============================] - 7s 3ms/step - loss: 0.0424 - accuracy: 0.9872 - val_loss: 0.0337 - val_accuracy: 0.9895\n",
      "Epoch 2/3\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0329 - accuracy: 0.9907 - val_loss: 0.0363 - val_accuracy: 0.9877\n",
      "Epoch 3/3\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0253 - accuracy: 0.9929 - val_loss: 0.0355 - val_accuracy: 0.9882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x149c762a0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.0,\n",
    "        final_sparsity=0.5,\n",
    "        begin_step=0,\n",
    "        end_step=np.ceil(X_train.shape[0] / 32).astype(np.int32) * 3\n",
    "    )\n",
    "}\n",
    "\n",
    "pruned_model = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "pruned_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "pruned_model.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=3,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[tfmot.sparsity.keras.UpdatePruningStep()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f7de6e82-c690-44f1-8a68-b4680f901136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06884318590164185, 0.9789999723434448]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f06526d6-02f6-4750-ad7f-aa910a63a9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_flatte  (None, 784)               1         \n",
      " n (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense   (None, 100)               156902    \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 10)                2012      \n",
      " 1 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 158915 (620.77 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 79405 (310.19 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pruned_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33834402-b947-4490-84fb-4248a03c3b0d",
   "metadata": {},
   "source": [
    "<h3 style='color:blue'>(2) Quantification post-formation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0aecc1-1b0b-4d0f-aee8-bbf8fff8c71b",
   "metadata": {},
   "source": [
    "**Sans quantification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "54f31024-41f5-4fd6-8229-1c9f21d3b9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmp1lvb88h_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmp1lvb88h_/assets\n",
      "W0000 00:00:1746831642.227472  782987 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1746831642.227489  782987 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2025-05-10 00:00:42.227711: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmp1lvb88h_\n",
      "2025-05-10 00:00:42.228577: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-05-10 00:00:42.228592: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmp1lvb88h_\n",
      "2025-05-10 00:00:42.236673: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2025-05-10 00:00:42.265621: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmp1lvb88h_\n",
      "2025-05-10 00:00:42.274444: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 46732 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873b589-cc54-4acf-89af-39a0afc2d02b",
   "metadata": {},
   "source": [
    "**Avec quantification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "19d45684-7293-4d6e-ad60-74fae51f41b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmpj020c4r6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmpj020c4r6/assets\n",
      "W0000 00:00:1746831644.916441  782987 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1746831644.916455  782987 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2025-05-10 00:00:44.916640: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmpj020c4r6\n",
      "2025-05-10 00:00:44.917439: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-05-10 00:00:44.917450: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmpj020c4r6\n",
      "2025-05-10 00:00:44.924925: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2025-05-10 00:00:44.953496: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmpj020c4r6\n",
      "2025-05-10 00:00:44.961985: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 45329 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Convertir en TFLite avec quantification\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "752d5c09-c9e5-4655-ad09-7465efc54592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319936"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "196de91d-b7a4-4f7e-a5b1-21ad935cfc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84816"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "65005cce-9de5-47f8-afbb-f8428f716e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tflite_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "135d6d41-05a2-4267-aead-f85ac78d6e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tflite_quant_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144ed9bd-5447-4b17-b4f2-3dead9683d5b",
   "metadata": {},
   "source": [
    "<h3 style='color:blue'>(3) Quantization aware training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "888431a2-7b60-49b6-9cd8-58dce78f20c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_1 (Quantize  (None, 28, 28)            3         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " quant_flatten (QuantizeWra  (None, 784)               1         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense (QuantizeWrapp  (None, 100)               78505     \n",
      " erV2)                                                           \n",
      "                                                                 \n",
      " quant_dense_1 (QuantizeWra  (None, 10)                1015      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79524 (310.64 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 14 (56.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# Créer un modèle avec awareness de quantification\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# Recompiler le modèle\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Afficher le résumé du modèle avec quantification\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dc6033f7-59e8-46ee-82d3-f5a9ee57993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.0820 - val_accuracy: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x1491d4e30>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraîner le modèle conscient de la quantification\n",
    "q_aware_model.fit(X_train, y_train, epochs=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c0c24dac-3efc-4871-abbb-2ed761632f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0820 - accuracy: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08204996585845947, 0.9757999777793884]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e028a56d-7377-4384-af08-d50e4c7dc58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmpiqgkx_vq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmpiqgkx_vq/assets\n",
      "/opt/anaconda3/lib/python3.12/site-packages/tensorflow/lite/python/convert.py:964: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1746831658.973414  782987 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1746831658.973427  782987 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2025-05-10 00:00:58.973647: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmpiqgkx_vq\n",
      "2025-05-10 00:00:58.975852: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-05-10 00:00:58.975877: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmpiqgkx_vq\n",
      "2025-05-10 00:00:58.991683: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2025-05-10 00:00:59.038814: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: /var/folders/27/pfjs1z692ml4r915h67q79x40000gn/T/tmpiqgkx_vq\n",
      "2025-05-10 00:00:59.054075: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 80428 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Convertir le modèle conscient de la quantification en TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_qaware_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "67b93d12-2781-4691-9a03-fc91eae395a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82712"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflite_qaware_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8426fb98-0584-4384-a51d-22201b00af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tflite_qaware_model.tflite\", 'wb') as f:\n",
    "    f.write(tflite_qaware_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba95e40-8fa8-4894-bbb7-d7363fc6e315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b9f77-df3b-485e-852d-bd353fcdb747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
